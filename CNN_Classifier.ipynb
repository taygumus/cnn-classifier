{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"MLQYokNgUAOt"},"source":["from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = 'all'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"utO69bC-U7GL"},"source":["import os\n","import tensorflow as tf\n","import numpy as np\n","\n","SEED = 1200\n","tf.random.set_seed(SEED)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OMbP5BLqZoyA","outputId":"9ef45298-dd6b-4b7a-8735-de7f8dce1ec7"},"source":["# Run this cell only if you are using Colab with Drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rg_JVKcIhfBn"},"source":["# Run this cell only if you are using Colab with Drive\n","\n","!unzip '/content/drive/My Drive/ANN_Projects/artificial-neural-networks-and-deep-learning'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wRKdZjDVNZEu","outputId":"10926bd1-bd2a-435b-acac-3c3370d2804d"},"source":["!ls '/content/MaskDataset'\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test  train_gt.json  training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6rB7QESKNc_V","outputId":"cd2f386d-fc47-42e1-9abe-331c375190d5"},"source":["import pandas as pd\n","import json\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","dataset_dir = '/content/MaskDataset'\n","with open(os.path.join(dataset_dir,'train_gt.json')) as f: train_gt = json.load(f)\n","\n","dataframe = pd.DataFrame(train_gt.items())\n","dataframe.rename(columns = {0:'filename', 1:'class'}, inplace = True)\n","dataframe['class'] = dataframe['class'].astype(str)\n","\n","# Batch size\n","bs = 10\n","\n","# Img shape\n","img_h = 512\n","img_w = 512\n","\n","# Class numbers\n","num_classes = 3\n","\n","# Fraction of images reserved for validation\n","validation_split = 0.15\n","\n","# Data generator\n","data_gen = ImageDataGenerator(rescale=1./255,\n","                              validation_split=validation_split)\n","\n","# Training directory\n","training_dir = os.path.join(dataset_dir, 'training')\n","\n","train_gen = data_gen.flow_from_dataframe(dataframe,\n","                                         training_dir,\n","                                         batch_size=bs,\n","                                         target_size=(img_h, img_w),\n","                                         class_mode='categorical',\n","                                         shuffle=True,\n","                                         seed=SEED,\n","                                         subset='training')\n","\n","valid_gen = data_gen.flow_from_dataframe(dataframe,\n","                                         training_dir,\n","                                         batch_size=bs,\n","                                         target_size=(img_h, img_w),\n","                                         class_mode='categorical',\n","                                         shuffle=True,\n","                                         seed=SEED,\n","                                         subset='validation')\n","# Training\n","train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n","train_dataset = train_dataset.repeat()\n","\n","# Validation\n","valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen,\n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n","valid_dataset = valid_dataset.repeat()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 4772 validated image filenames belonging to 3 classes.\n","Found 842 validated image filenames belonging to 3 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2Ty7LZ8bNOEP"},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","iterator = iter(valid_dataset)\n","\n","augmented_img, target = next(iterator)\n","augmented_img = np.array(augmented_img[0])\n","augmented_img = augmented_img * 255\n","\n","plt.imshow(np.uint8(augmented_img))\n","plt.plot()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PaJ801SDmUuh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b8e9f016-45e7-4549-c75e-e0c1d6c902eb"},"source":["# CNN Architecture\n","\n","model = tf.keras.Sequential()\n","\n","# Features extraction\n","model.add(tf.keras.layers.Conv2D(filters=8, kernel_size=(3, 3), strides=(1, 1), padding='same', input_shape=[img_h, img_w, 3]))\n","model.add(tf.keras.layers.ReLU())\n","model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n","\n","model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n","model.add(tf.keras.layers.ReLU())\n","model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n","\n","model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n","model.add(tf.keras.layers.ReLU())\n","model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n","\n","model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n","model.add(tf.keras.layers.ReLU())\n","model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n","\n","model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n","model.add(tf.keras.layers.ReLU())\n","model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n","\n","# Classifier\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(units=16, activation='relu'))\n","model.add(tf.keras.layers.Dense(units=8, activation='relu'))\n","model.add(tf.keras.layers.Dense(units=4, activation='relu'))\n","model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 512, 512, 8)       224       \n","_________________________________________________________________\n","re_lu (ReLU)                 (None, 512, 512, 8)       0         \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 256, 256, 8)       0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 256, 256, 16)      1168      \n","_________________________________________________________________\n","re_lu_1 (ReLU)               (None, 256, 256, 16)      0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 128, 128, 16)      0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 128, 128, 32)      4640      \n","_________________________________________________________________\n","re_lu_2 (ReLU)               (None, 128, 128, 32)      0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 64, 64, 32)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 64, 64, 64)        18496     \n","_________________________________________________________________\n","re_lu_3 (ReLU)               (None, 64, 64, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 32, 32, 128)       73856     \n","_________________________________________________________________\n","re_lu_4 (ReLU)               (None, 32, 32, 128)       0         \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 32768)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 16)                524304    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 8)                 136       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 4)                 36        \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 3)                 15        \n","=================================================================\n","Total params: 622,875\n","Trainable params: 622,875\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CyWd0xS622DR"},"source":["# Loss\n","loss = tf.keras.losses.CategoricalCrossentropy()\n","\n","# Learning rate\n","lr = 1e-3\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","\n","# Validation metrics\n","metrics = ['accuracy']\n","\n","# Compile model\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_8eSR7jc3dFG"},"source":["import os\n","from datetime import datetime\n","\n","project_dir = '/content/drive/My Drive/ANN_Projects'\n","\n","exps_dir = os.path.join(project_dir, 'classification_experiments')\n","if not os.path.exists(exps_dir):\n","    os.makedirs(exps_dir)\n","\n","now = datetime.now().strftime('%b%d_%H-%M-%S')\n","\n","model_name = 'CNN'\n","exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n","if not os.path.exists(exp_dir):\n","    os.makedirs(exp_dir)\n","\n","callbacks = []\n","\n","# Model Checkpoint\n","ckpt_dir = os.path.join(exp_dir, 'ckpts')\n","if not os.path.exists(ckpt_dir):\n","    os.makedirs(ckpt_dir)\n","\n","ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'),\n","                                                   save_weights_only=True)\n","callbacks.append(ckpt_callback)\n","\n","# Visualize Learning on Tensorboard\n","tb_dir = os.path.join(exp_dir, 'tb_logs')\n","if not os.path.exists(tb_dir):\n","    os.makedirs(tb_dir)\n","\n","tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n","                                             profile_batch=0,\n","                                             histogram_freq=1)\n","callbacks.append(tb_callback)\n","\n","# Early Stopping\n","early_stop = True\n","if early_stop:\n","    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n","                                                   patience=10,\n","                                                   restore_best_weights=True)\n","    callbacks.append(es_callback)\n","\n","ckpt_dir"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u94pCUJJ7TuG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8d60276e-1322-4e26-d1ee-dc47d50ea144"},"source":["# model.load_weights('/content/drive/My Drive/ANN_Projects/classification_experiments/cp_13.ckpt')\n","\n","model.fit(x=train_dataset,\n","          epochs=100,\n","          steps_per_epoch=len(train_gen),\n","          validation_data=valid_dataset,\n","          validation_steps=len(valid_gen),\n","          callbacks=callbacks)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","478/478 [==============================] - 64s 135ms/step - loss: 1.0667 - accuracy: 0.3841 - val_loss: 1.6012 - val_accuracy: 0.0000e+00\n","Epoch 2/100\n","478/478 [==============================] - 64s 135ms/step - loss: 1.0492 - accuracy: 0.3971 - val_loss: 1.3311 - val_accuracy: 0.0000e+00\n","Epoch 3/100\n","478/478 [==============================] - 64s 135ms/step - loss: 1.0163 - accuracy: 0.4189 - val_loss: 1.1701 - val_accuracy: 0.0000e+00\n","Epoch 4/100\n","478/478 [==============================] - 65s 135ms/step - loss: 0.8520 - accuracy: 0.5897 - val_loss: 0.9170 - val_accuracy: 0.9133\n","Epoch 5/100\n","478/478 [==============================] - 65s 135ms/step - loss: 0.7283 - accuracy: 0.6846 - val_loss: 0.8361 - val_accuracy: 0.8527\n","Epoch 6/100\n","478/478 [==============================] - 65s 136ms/step - loss: 0.6692 - accuracy: 0.7091 - val_loss: 0.5205 - val_accuracy: 0.9893\n","Epoch 7/100\n","478/478 [==============================] - 65s 135ms/step - loss: 0.6107 - accuracy: 0.7418 - val_loss: 0.4149 - val_accuracy: 0.9893\n","Epoch 8/100\n","478/478 [==============================] - 65s 136ms/step - loss: 0.5716 - accuracy: 0.7496 - val_loss: 0.4053 - val_accuracy: 0.9620\n","Epoch 9/100\n","478/478 [==============================] - 65s 136ms/step - loss: 0.5152 - accuracy: 0.7808 - val_loss: 0.5762 - val_accuracy: 0.8646\n","Epoch 10/100\n","478/478 [==============================] - 65s 136ms/step - loss: 0.4755 - accuracy: 0.7982 - val_loss: 0.5157 - val_accuracy: 0.8955\n","Epoch 11/100\n","478/478 [==============================] - 65s 136ms/step - loss: 0.4118 - accuracy: 0.8334 - val_loss: 0.2465 - val_accuracy: 0.9691\n","Epoch 12/100\n","478/478 [==============================] - 65s 136ms/step - loss: 0.3655 - accuracy: 0.8560 - val_loss: 0.3779 - val_accuracy: 0.9240\n","Epoch 13/100\n","478/478 [==============================] - 65s 136ms/step - loss: 0.2905 - accuracy: 0.8860 - val_loss: 0.5562 - val_accuracy: 0.8907\n","Epoch 14/100\n","478/478 [==============================] - 65s 136ms/step - loss: 0.2385 - accuracy: 0.9114 - val_loss: 0.5315 - val_accuracy: 0.8907\n","Epoch 15/100\n","478/478 [==============================] - 65s 136ms/step - loss: 0.1920 - accuracy: 0.9288 - val_loss: 0.4474 - val_accuracy: 0.9204\n","Epoch 16/100\n","478/478 [==============================] - 65s 137ms/step - loss: 0.1737 - accuracy: 0.9396 - val_loss: 0.4218 - val_accuracy: 0.9062\n","Epoch 17/100\n","478/478 [==============================] - 65s 137ms/step - loss: 0.1209 - accuracy: 0.9585 - val_loss: 0.3446 - val_accuracy: 0.9359\n","Epoch 18/100\n","478/478 [==============================] - 65s 136ms/step - loss: 0.1035 - accuracy: 0.9652 - val_loss: 1.3149 - val_accuracy: 0.8183\n","Epoch 19/100\n","478/478 [==============================] - 65s 137ms/step - loss: 0.1007 - accuracy: 0.9677 - val_loss: 0.5372 - val_accuracy: 0.9026\n","Epoch 20/100\n","478/478 [==============================] - 66s 138ms/step - loss: 0.1009 - accuracy: 0.9669 - val_loss: 0.4632 - val_accuracy: 0.9038\n","Epoch 21/100\n","478/478 [==============================] - 66s 137ms/step - loss: 0.0798 - accuracy: 0.9732 - val_loss: 0.8047 - val_accuracy: 0.8753\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fc0801b7e80>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"331aOb6D_IbN"},"source":["%load_ext tensorboard\n","%tensorboard --logdir /content/drive/My\\ Drive/ANN_Projects/classification_experiments/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kDU7cMQUcl0Q"},"source":["def create_csv(results, results_dir='./'):\n","\n","    csv_fname = 'results_'\n","    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n","\n","    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n","\n","        f.write('Id,Category\\n')\n","\n","        for key, value in results.items():\n","            f.write(key + ',' + str(value) + '\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yNJ2wI7BagHU"},"source":["from PIL import Image\n","import ntpath\n","\n","test_dir = os.path.join(dataset_dir, 'test')\n","image_filenames = next(os.walk(test_dir))[2]\n","images = pd.DataFrame(image_filenames)\n","\n","images.rename(columns = {0:'filename'}, inplace = True)\n","images['class'] = 'test'\n","\n","# Create a data generator for test images\n","test_gen = data_gen.flow_from_dataframe(images,\n","                                        test_dir,\n","                                        batch_size=bs,\n","                                        target_size=(img_h, img_w),\n","                                        class_mode='categorical',\n","                                        shuffle=False,\n","                                        seed=SEED)\n","\n","test_gen.reset()\n","\n","# Predict the classes for test images\n","predictions = model.predict_generator(test_gen, len(test_gen), verbose=1)\n","\n","results = {}\n","images = test_gen.filenames\n","i = 0\n","\n","for p in predictions:\n","  prediction = np.argmax(p)\n","  image_name = ntpath.basename(images[i])\n","  results[image_name] = str(prediction)\n","  i = i + 1\n","\n","create_csv(results,'/content/drive/My Drive/ANN_Projects/')"],"execution_count":null,"outputs":[]}]}